{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown\n\nimport gdown\n\nurl = 'https://drive.google.com/uc?id=1yxP8E8BGcQXqisWB6Dy2Z8wuD2-qxown'\n\ngdown.download(url, 'archivo.zip', quiet=False)\n\nimport zipfile\nimport os\n\n# Ruta del archivo ZIP en Google Drive\nzip_file_path = '/kaggle/working/archivo.zip'\n\n# Ruta donde deseas extraer los archivos\nextract_path = '/content/extracted_files'\n\n# Extraer el contenido del archivo ZIP\nwith zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n\n# Listar los archivos extraídos\nos.listdir(extract_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T19:34:15.160704Z","iopub.execute_input":"2024-07-02T19:34:15.161083Z","iopub.status.idle":"2024-07-02T19:35:26.104876Z","shell.execute_reply.started":"2024-07-02T19:34:15.161052Z","shell.execute_reply":"2024-07-02T19:35:26.103722Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1yxP8E8BGcQXqisWB6Dy2Z8wuD2-qxown\nFrom (redirected): https://drive.google.com/uc?id=1yxP8E8BGcQXqisWB6Dy2Z8wuD2-qxown&confirm=t&uuid=19d5f9bc-9282-4936-b5d8-6e93b70c3466\nTo: /kaggle/working/archivo.zip\n100%|██████████| 2.18G/2.18G [00:33<00:00, 64.9MB/s]\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['train.csv', 'test', 'train', 'sample.csv']"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\nfrom sklearn.model_selection import train_test_split\nimport cv2\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:35:58.079576Z","iopub.execute_input":"2024-07-02T19:35:58.079971Z","iopub.status.idle":"2024-07-02T19:36:11.893436Z","shell.execute_reply.started":"2024-07-02T19:35:58.079939Z","shell.execute_reply":"2024-07-02T19:36:11.892577Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-02 19:36:00.478737: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-02 19:36:00.478849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-02 19:36:00.616549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv('/content/extracted_files/train.csv')\ntrain_df['filename'] = train_df['ID'] + '_' + train_df['location'] + '.jpg'\ntrain_df['level'] = train_df['level'].apply(lambda x: '0' if x == 0 else '1')\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:36:32.754124Z","iopub.execute_input":"2024-07-02T19:36:32.755467Z","iopub.status.idle":"2024-07-02T19:36:32.830704Z","shell.execute_reply.started":"2024-07-02T19:36:32.755427Z","shell.execute_reply":"2024-07-02T19:36:32.829574Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                 ID location level  \\\n0  d3d9446802a44259755d38e6d163e820     left     0   \n1  d3d9446802a44259755d38e6d163e820    right     0   \n2  c51ce410c124a10e0db5e4b97fc2af39     left     0   \n3  c51ce410c124a10e0db5e4b97fc2af39    right     0   \n4  9bf31c7ff062936a96d3c8bd1f8f2ff3     left     1   \n\n                                     filename  \n0   d3d9446802a44259755d38e6d163e820_left.jpg  \n1  d3d9446802a44259755d38e6d163e820_right.jpg  \n2   c51ce410c124a10e0db5e4b97fc2af39_left.jpg  \n3  c51ce410c124a10e0db5e4b97fc2af39_right.jpg  \n4   9bf31c7ff062936a96d3c8bd1f8f2ff3_left.jpg  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>location</th>\n      <th>level</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d3d9446802a44259755d38e6d163e820</td>\n      <td>left</td>\n      <td>0</td>\n      <td>d3d9446802a44259755d38e6d163e820_left.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d3d9446802a44259755d38e6d163e820</td>\n      <td>right</td>\n      <td>0</td>\n      <td>d3d9446802a44259755d38e6d163e820_right.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c51ce410c124a10e0db5e4b97fc2af39</td>\n      <td>left</td>\n      <td>0</td>\n      <td>c51ce410c124a10e0db5e4b97fc2af39_left.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c51ce410c124a10e0db5e4b97fc2af39</td>\n      <td>right</td>\n      <td>0</td>\n      <td>c51ce410c124a10e0db5e4b97fc2af39_right.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9bf31c7ff062936a96d3c8bd1f8f2ff3</td>\n      <td>left</td>\n      <td>1</td>\n      <td>9bf31c7ff062936a96d3c8bd1f8f2ff3_left.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n#import os","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:36:38.023963Z","iopub.execute_input":"2024-07-02T19:36:38.024631Z","iopub.status.idle":"2024-07-02T19:36:38.041542Z","shell.execute_reply.started":"2024-07-02T19:36:38.024576Z","shell.execute_reply":"2024-07-02T19:36:38.040194Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Definir parámetros de imagen y entrenamiento\nimg_height, img_width = 224, 224\nbatch_size = 32\nnum_classes = 2\n\n# Dividir en conjunto de entrenamiento y validación\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['level'], random_state=42)\n\n# Generadores de datos\ntrain_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, rotation_range=40,width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=[0.8, 1.2],fill_mode='nearest')\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory='/content/extracted_files/train/train',\n    x_col='filename',\n    y_col='level',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    directory='/content/extracted_files/train/train',\n    x_col='filename',\n    y_col='level',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary'\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:36:41.468920Z","iopub.execute_input":"2024-07-02T19:36:41.469279Z","iopub.status.idle":"2024-07-02T19:36:41.900562Z","shell.execute_reply.started":"2024-07-02T19:36:41.469254Z","shell.execute_reply":"2024-07-02T19:36:41.899570Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 19670 validated image filenames belonging to 2 classes.\nFound 4918 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Construir el modelo\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n\n#agregandole regularizacion l2 para evitar sobreajuste\nfrom tensorflow.keras.regularizers import L2\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu', kernel_regularizer=L2(0.01))(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\npredictions = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:36:51.129034Z","iopub.execute_input":"2024-07-02T19:36:51.129452Z","iopub.status.idle":"2024-07-02T19:36:54.257640Z","shell.execute_reply.started":"2024-07-02T19:36:51.129418Z","shell.execute_reply":"2024-07-02T19:36:54.256807Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n\ncallbacks = [\n    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min'),\n    EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, mode='min', min_lr=1e-7)\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:36:59.511903Z","iopub.execute_input":"2024-07-02T19:36:59.512273Z","iopub.status.idle":"2024-07-02T19:36:59.533285Z","shell.execute_reply.started":"2024-07-02T19:36:59.512244Z","shell.execute_reply":"2024-07-02T19:36:59.532475Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\n#Balancear clases\ny_train = train_df['level'].values\n\n# Calcular los pesos de las clases\nclass_weights = compute_class_weight(class_weight=\"balanced\",classes=np.unique(y_train),y=y_train)\n\nclass_weight_dict = dict(enumerate(class_weights))","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:37:04.594542Z","iopub.execute_input":"2024-07-02T19:37:04.594952Z","iopub.status.idle":"2024-07-02T19:37:04.624826Z","shell.execute_reply.started":"2024-07-02T19:37:04.594921Z","shell.execute_reply":"2024-07-02T19:37:04.623615Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Entrenar el modelo\nmodel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // batch_size,\n    epochs=25,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // batch_size,\n    class_weight=class_weight_dict,\n    callbacks=callbacks\n)\n\n# Guardar el modelo\nmodel.save('retinopathy_detection.keras')","metadata":{"execution":{"iopub.status.busy":"2024-07-02T19:37:13.359491Z","iopub.execute_input":"2024-07-02T19:37:13.360429Z","iopub.status.idle":"2024-07-02T20:36:52.514038Z","shell.execute_reply.started":"2024-07-02T19:37:13.360395Z","shell.execute_reply":"2024-07-02T20:36:52.512955Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/614\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:10:24\u001b[0m 25s/step - accuracy: 0.5000 - loss: 14.5230","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1719949058.816392     122 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1719949058.871718     122 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m529/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m43s\u001b[0m 515ms/step - accuracy: 0.4879 - loss: 8.1750","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719949330.898628     120 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.4900 - loss: 7.6894","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719949375.196470     122 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 546ms/step - accuracy: 0.4900 - loss: 7.6841 - val_accuracy: 0.7337 - val_loss: 1.8457 - learning_rate: 1.0000e-04\nEpoch 2/25\n\u001b[1m  1/614\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 74ms/step - accuracy: 0.4688 - loss: 1.4782","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\nW0000 00:00:1719949395.945635     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4688 - loss: 1.4782 - val_accuracy: 0.9091 - val_loss: 1.1440 - learning_rate: 1.0000e-04\nEpoch 3/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 515ms/step - accuracy: 0.4909 - loss: 1.3781 - val_accuracy: 0.2655 - val_loss: 5.1130 - learning_rate: 1.0000e-04\nEpoch 4/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131us/step - accuracy: 0.5625 - loss: 0.9957 - val_accuracy: 0.2727 - val_loss: 4.3972 - learning_rate: 1.0000e-04\nEpoch 5/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 509ms/step - accuracy: 0.5164 - loss: 1.0865 - val_accuracy: 0.2904 - val_loss: 1.0961 - learning_rate: 1.0000e-04\nEpoch 6/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4688 - loss: 0.9977 - val_accuracy: 0.7273 - val_loss: 0.8305 - learning_rate: 1.0000e-04\nEpoch 7/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 514ms/step - accuracy: 0.5089 - loss: 0.9652 - val_accuracy: 0.6150 - val_loss: 0.8469 - learning_rate: 1.0000e-04\nEpoch 8/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132us/step - accuracy: 0.3438 - loss: 0.8997 - val_accuracy: 0.3636 - val_loss: 1.0144 - learning_rate: 1.0000e-04\nEpoch 9/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 518ms/step - accuracy: 0.5019 - loss: 0.8910 - val_accuracy: 0.7347 - val_loss: 0.8742 - learning_rate: 1.0000e-04\nEpoch 10/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135us/step - accuracy: 0.5312 - loss: 0.8948 - val_accuracy: 0.6818 - val_loss: 1.1093 - learning_rate: 1.0000e-04\nEpoch 11/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 514ms/step - accuracy: 0.5234 - loss: 0.8320 - val_accuracy: 0.7339 - val_loss: 0.7062 - learning_rate: 1.0000e-04\nEpoch 12/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 0.8579 - val_accuracy: 0.8636 - val_loss: 0.5168 - learning_rate: 1.0000e-04\nEpoch 13/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 525ms/step - accuracy: 0.5107 - loss: 0.8105 - val_accuracy: 0.7345 - val_loss: 0.6977 - learning_rate: 1.0000e-04\nEpoch 14/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133us/step - accuracy: 0.5312 - loss: 0.7769 - val_accuracy: 0.6364 - val_loss: 0.8332 - learning_rate: 1.0000e-04\nEpoch 15/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 515ms/step - accuracy: 0.5067 - loss: 0.7822 - val_accuracy: 0.7345 - val_loss: 0.9360 - learning_rate: 1.0000e-04\nEpoch 16/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129us/step - accuracy: 0.5312 - loss: 0.6551 - val_accuracy: 0.7273 - val_loss: 1.1217 - learning_rate: 1.0000e-04\nEpoch 17/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 519ms/step - accuracy: 0.5185 - loss: 0.7572 - val_accuracy: 0.2659 - val_loss: 4.8733 - learning_rate: 1.0000e-04\nEpoch 18/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134us/step - accuracy: 0.5312 - loss: 0.8680 - val_accuracy: 0.1818 - val_loss: 5.3115 - learning_rate: 1.0000e-05\nEpoch 19/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 531ms/step - accuracy: 0.5310 - loss: 0.7438 - val_accuracy: 0.6614 - val_loss: 0.6936 - learning_rate: 1.0000e-05\nEpoch 20/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131us/step - accuracy: 0.4062 - loss: 0.7612 - val_accuracy: 0.7273 - val_loss: 0.6645 - learning_rate: 1.0000e-05\nEpoch 21/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 512ms/step - accuracy: 0.5293 - loss: 0.7349 - val_accuracy: 0.2988 - val_loss: 0.8717 - learning_rate: 1.0000e-05\nEpoch 22/25\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122us/step - accuracy: 0.4062 - loss: 0.6849 - val_accuracy: 0.3636 - val_loss: 0.8392 - learning_rate: 1.0000e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in base_model.layers[-10:]:\n    layer.trainable = True\n\nmodel.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Fine tunning\nmodel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // batch_size,\n    epochs=10,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // batch_size,\n    callbacks=callbacks\n)\n\n# Guardar el modelo\nmodel.save('retinopathy_detection_finetunning.keras')","metadata":{"execution":{"iopub.status.busy":"2024-07-02T20:38:50.746629Z","iopub.execute_input":"2024-07-02T20:38:50.747025Z","iopub.status.idle":"2024-07-02T21:04:16.425413Z","shell.execute_reply.started":"2024-07-02T20:38:50.746993Z","shell.execute_reply":"2024-07-02T21:04:16.424369Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m  2/614\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 106ms/step - accuracy: 0.4453 - loss: 0.8759 ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719952752.882384     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m573/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m19s\u001b[0m 476ms/step - accuracy: 0.5229 - loss: 0.8234","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719953025.248040     120 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - accuracy: 0.5248 - loss: 0.8219","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719953045.677468     122 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 504ms/step - accuracy: 0.5248 - loss: 0.8219 - val_accuracy: 0.6612 - val_loss: 0.7696 - learning_rate: 1.0000e-05\nEpoch 2/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5312 - loss: 0.7448 - val_accuracy: 0.6364 - val_loss: 0.7617 - learning_rate: 1.0000e-05\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719953063.902185     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 477ms/step - accuracy: 0.6324 - loss: 0.7540 - val_accuracy: 0.6985 - val_loss: 0.7150 - learning_rate: 1.0000e-05\nEpoch 4/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127us/step - accuracy: 0.7500 - loss: 0.6967 - val_accuracy: 0.8636 - val_loss: 0.6178 - learning_rate: 1.0000e-05\nEpoch 5/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 471ms/step - accuracy: 0.7100 - loss: 0.7149 - val_accuracy: 0.7239 - val_loss: 0.6727 - learning_rate: 1.0000e-05\nEpoch 6/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127us/step - accuracy: 0.6250 - loss: 0.7820 - val_accuracy: 0.6818 - val_loss: 0.7422 - learning_rate: 1.0000e-05\nEpoch 7/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 481ms/step - accuracy: 0.7231 - loss: 0.6915 - val_accuracy: 0.7341 - val_loss: 0.6725 - learning_rate: 1.0000e-05\nEpoch 8/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128us/step - accuracy: 0.7188 - loss: 0.6577 - val_accuracy: 0.8182 - val_loss: 0.6008 - learning_rate: 1.0000e-05\nEpoch 9/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 489ms/step - accuracy: 0.7277 - loss: 0.6759 - val_accuracy: 0.7339 - val_loss: 0.6822 - learning_rate: 1.0000e-05\nEpoch 10/10\n\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134us/step - accuracy: 0.7188 - loss: 0.6728 - val_accuracy: 0.6818 - val_loss: 0.7348 - learning_rate: 1.0000e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Generador para el conjunto de prueba\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    '/content/extracted_files/test',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode=None,\n    shuffle=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:04:57.609267Z","iopub.execute_input":"2024-07-02T21:04:57.609997Z","iopub.status.idle":"2024-07-02T21:04:57.901292Z","shell.execute_reply.started":"2024-07-02T21:04:57.609966Z","shell.execute_reply":"2024-07-02T21:04:57.900453Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Found 10538 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predicciones\npredictions = model.predict(test_generator, steps=len(test_generator), verbose=1)\n# Extraer puntajes flotantes\nscores = predictions[:, 0]","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:13:33.326555Z","iopub.execute_input":"2024-07-02T21:13:33.326952Z","iopub.status.idle":"2024-07-02T21:14:10.575489Z","shell.execute_reply.started":"2024-07-02T21:13:33.326924Z","shell.execute_reply":"2024-07-02T21:14:10.574632Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 112ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nfilenames = [os.path.splitext(os.path.basename(f))[0] for f in test_generator.filenames]\n\n# Verificar la longitud de ambas listas\nassert len(filenames) == len(scores), \"Las longitudes de filenames y scores no coinciden\"\n\n# Crear DataFrame de resultados\nsubmission_df = pd.DataFrame({\n    'ID': filenames,\n    'score': scores\n})\n\nsubmission_df.to_csv('submissionDR.csv', index=False)\n\nprint(submission_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:14:16.799413Z","iopub.execute_input":"2024-07-02T21:14:16.799905Z","iopub.status.idle":"2024-07-02T21:14:16.883632Z","shell.execute_reply.started":"2024-07-02T21:14:16.799876Z","shell.execute_reply":"2024-07-02T21:14:16.882662Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"                                       ID     score\n0   0002ac0d783338cfeab0b2bdbd872cda_left  0.468029\n1  0002ac0d783338cfeab0b2bdbd872cda_right  0.496906\n2   000e82a96e908e73372bed4e5cb98096_left  0.460893\n3  000e82a96e908e73372bed4e5cb98096_right  0.482462\n4   0012a83c1e6cda9d73a22dbeaac47e8f_left  0.486997\n","output_type":"stream"}]}]}